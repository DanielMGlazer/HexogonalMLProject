{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.mlab as mlab\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow.keras.losses\n",
    "import math\n",
    "import datetime\n",
    "from my_classes import DataGenerator,STMImage\n",
    "from scipy.ndimage.filters import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 5, 5, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 264       \n",
      "=================================================================\n",
      "Total params: 93,032\n",
      "Trainable params: 93,032\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_name='run7_03_standardized'\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "model=models.load_model(os.path.join('Models',model_name),compile=False)\n",
    "model.compile(optimizer='Adam', loss=root_mean_squared_error, metrics=['mse','mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     2,
     13,
     18
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ARRAY:Loads in a single testing image and plots its prediction vs true labels\n",
    "#Method for separting label array into useful data points\n",
    "def split_label(labels):\n",
    "    center_atom=np.array([labels[0],labels[1]])*32\n",
    "    neighborvec1=np.array([labels[2],labels[3]])*32\n",
    "    neighborvec2=np.array([labels[4],labels[5]])*32\n",
    "    neighborvec3=np.array([labels[6],labels[7]])*32\n",
    "    neighbors=[]\n",
    "    neighbors.append(center_atom+neighborvec1)\n",
    "    neighbors.append(center_atom+neighborvec2)\n",
    "    neighbors.append(center_atom+neighborvec3)\n",
    "    return center_atom , neighbors \n",
    "#Methods for coloring in the central atom and labels on the images.\n",
    "def plot_labels():\n",
    "    plt.plot(center_atom[0],center_atom[1],'o',color='black')\n",
    "    plt.plot(neighbors[0][0],neighbors[0][1],'o',color='red')\n",
    "    plt.plot(neighbors[1][0],neighbors[1][1],'o',color='green')\n",
    "    plt.plot(neighbors[2][0],neighbors[2][1],'o',color='blue')\n",
    "def plot_test_labels():\n",
    "    plt.plot(center_atom_t[0],center_atom_t[1],'o',color='xkcd:gray')\n",
    "    plt.plot(neighbors_t[0][0],neighbors_t[0][1],'o',color='xkcd:dark red')\n",
    "    plt.plot(neighbors_t[1][0],neighbors_t[1][1],'o',color='xkcd:dark green')\n",
    "    plt.plot(neighbors_t[2][0],neighbors_t[2][1],'o',color='xkcd:dark blue')\n",
    "\n",
    "    \n",
    "\n",
    "model_name='run7_03_standardized'\n",
    "test_dataset_dir ='\\\\Users\\\\danie\\\\Penn_State_REU_Jupyter\\\\Hexagon ML Project GitHub\\\\Training_set_7_01'\n",
    "prediction_dir=os.path.join(\"Training_Set_Predictions\",model_name)\n",
    "dft = pd.read_csv(os.path.join(test_dataset_dir,\"training_dataframe.csv\"))\n",
    "dfp= pd.read_csv(os.path.join(prediction_dir,\"predictions_dataframe.csv\"))\n",
    "\n",
    "\n",
    "index=21642\n",
    "im_filename=dft['filename'][index]\n",
    "atom_size=dft['atom_size'][index]\n",
    "corr=dft['corr'][index]+.1\n",
    "\n",
    "#test_im=np.asarray(image.load_img(os.path.join(test_dataset_dir,im_filename)))\n",
    "test_im=np.load(os.path.join(test_dataset_dir,im_filename))\n",
    "im_tensor=np.reshape(test_im,(32,32,1))\n",
    "im_tensor=np.expand_dims(im_tensor, axis=0)\n",
    "\n",
    "label_names=['x_coord','y_coord','neighbor1x','neighbor1y','neighbor2x','neighbor2y','neighbor3x','neighbor3y']\n",
    "test_labels=dft[label_names].loc[index].to_numpy()\n",
    "prediction_labels=dfp[label_names].loc[index].to_numpy()\n",
    "\n",
    "center_atom_t,neighbors_t=split_label(test_labels)\n",
    "center_atom,neighbors=split_label(prediction_labels)\n",
    "\n",
    "#os.makedirs(os.path.join('Prediction_Plots',datetime.datetime.now().strftime(\"%m_%d\")))\n",
    "prediction_plots_dir=os.path.join('Prediction_Plots',datetime.datetime.now().strftime(\"%m_%d\"))\n",
    "\n",
    "# %matplotlib notebook\n",
    "# %matplotlib inline\n",
    "\n",
    "\n",
    "im=STMImage(test_im)\n",
    "fig = plt.figure(figsize = (8, 8))\n",
    "ax = plt.subplot(1,1,1)\n",
    "ax.imshow(im.image)\n",
    "ax.axis('off')\n",
    "plot_test_labels()\n",
    "#plot_labels()\n",
    "\n",
    "\n",
    "# im_tensor=STMImage(test_im).image\n",
    "# im_tensor=np.expand_dims(im_tensor, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node model/conv2d/StatefulPartitionedCall/StatefulPartitionedCall/Conv2D}}]] [Op:__inference_distributed_function_1819]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-6735499d0699>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mactivation_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayer_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mactivations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactivation_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m   1014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[1;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m               \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m               total_epochs=1)\n\u001b[0m\u001b[0;32m    476\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    636\u001b[0m               *args, **kwds)\n\u001b[0;32m    637\u001b[0m       \u001b[1;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node model/conv2d/StatefulPartitionedCall/StatefulPartitionedCall/Conv2D}}]] [Op:__inference_distributed_function_1819]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "layer_outputs=[layer.output for layer in model.layers[:8]]\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "activations = activation_model.predict(im_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_name='run7_03_standardized'\n",
    "plot_dir=os.path.join(\"Layer Activations\",model_name)\n",
    "#os.makedirs(plot_dir)\n",
    "layer_names = []                                                          \n",
    "for layer in model.layers[:8]:                                            \n",
    "    layer_names.append(layer.name)                                        \n",
    "\n",
    "images_per_row = 16\n",
    "\n",
    "plt.figure()\n",
    "for layer_name, layer_activation in zip(layer_names, activations):      \n",
    "    n_features = layer_activation.shape[-1]                               \n",
    "\n",
    "    size = layer_activation.shape[1]                                      \n",
    "\n",
    "    n_cols = n_features // images_per_row                                 \n",
    "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "\n",
    "    for col in range(n_cols):                                             \n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[0,\n",
    "                                             :, :,\n",
    "                                             col * images_per_row + row]\n",
    "            channel_image -= channel_image.mean()                         \n",
    "            channel_image /= channel_image.std()\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            display_grid[col * size : (col + 1) * size,                   \n",
    "                         row * size : (row + 1) * size] = channel_image\n",
    "\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                        scale * display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
    "    plt.savefig(os.path.join(plot_dir,'run6_24_newdataset activations'+layer_name+'.png'))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
