{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "import os, shutil\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageColor\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_dir ='\\\\Users\\\\danie\\\\Penn_State_REU_Jupyter\\\\Hexagon ML Project\\\\Training_set_6_9' \n",
    "\n",
    "base_dir='\\\\Users\\\\danie\\\\Penn_State_REU_Jupyter\\\\Hexagon ML Project\\\\Training_base'\n",
    "train_dir = os.path.join(base_dir, 'train')                                \n",
    "os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'validation')                      \n",
    "os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir, 'test')                                  \n",
    "os.mkdir(test_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Loads labels and training data into two arrays, such that their indicies match\n",
    "train_targets1=[]\n",
    "with open(\"Training_set_6_9\\\\training_labels.json\",'r') as dict_contents:\n",
    "    train_targets_dict=json.load(dict_contents)\n",
    "\n",
    "train_images1 = []\n",
    "path = original_dataset_dir\n",
    "valid_images = [\".jpg\",\".gif\",\".png\",\".tga\"]\n",
    "for f in os.listdir(path):\n",
    "    ext = os.path.splitext(f)[1]\n",
    "    if ext.lower() not in valid_images:\n",
    "        continue\n",
    "    #print(f[10:-4])\n",
    "    train_images1.append(Image.open(os.path.join(path,f)))\n",
    "    train_targets1.append(train_targets_dict[str(f[10:-4])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[[13.5, 18.186533479473212],\n [[-7.0, 0.0], [3.5, 6.0621778264910695], [3.5, -6.0621778264910695]]]"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index_list=random.sample(range(len(train_images)),len(train_images))\n",
    "index_list=[12, 77, 11, 32, 35, 28, 58, 70, 0, 46, 64, 74, 13, 1, 19, 2, 57, 39, 56, 30, 71, 49, 38, 7, 47, 75, 43, 25, 5, 44, 18, 50, 51, 17, 21, 27, 48, 29, 6, 10, 8, 34, 76, 9, 69, 60, 62, 15, 65, 53, 59, 16, 24, 4, 55, 22, 63, 78, 73, 67, 20, 42, 68, 52, 26, 79, 36, 33, 45, 41, 37, 72, 14, 40, 66, 3, 54, 31, 61, 23]\n",
    "train_images=[]\n",
    "train_targets=[]\n",
    "for i in index_list:\n",
    "    train_images.append(train_images1[i])\n",
    "    train_labels.append(train_labels1[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'[12, 77, 11, 32, 35, 28, 58, 70, 0, 46, 64, 74, 13, 1, 19, 2, 57, 39, 56, 30, 71, 49, 38, 7, 47, 75, 43, 25, 5, 44, 18, 50, 51, 17, 21, 27, 48, 29, 6, 10, 8, 34, 76, 9, 69, 60, 62, 15, 65, 53, 59, 16, 24, 4, 55, 22, 63, 78, 73, 67, 20, 42, 68, 52, 26, 79, 36, 33, 45, 41, 37, 72, 14, 40, 66, 3, 54, 31, 61, 23]'"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "processing fold # 0\n"
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'PngImageFile'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-3e7d2e3430d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         [train_images[:i * num_val_samples],\n\u001b[0;32m     12\u001b[0m          train_images[(i + 1) * num_val_samples:]],\n\u001b[1;32m---> 13\u001b[1;33m         axis=0)\n\u001b[0m\u001b[0;32m     14\u001b[0m     partial_train_targets = np.concatenate(\n\u001b[0;32m     15\u001b[0m         [train_targets[:i * num_val_samples],\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'PngImageFile'"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "num_val_samples = len(train_images) // k\n",
    "num_epochs = 20\n",
    "all_mae_histories = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_images = train_images[i * num_val_samples: (i + 1) * num_val_samples]    \n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    partial_train_images = np.concatenate(                                     \n",
    "        [train_images[:i * num_val_samples],\n",
    "         train_images[(i + 1) * num_val_samples:]],\n",
    "         axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "         train_targets[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "\n",
    "    model = build_model()                                                    \n",
    "    history= model.fit(partial_train_images, partial_train_targets,\n",
    "                        validation_data=(val_images, val_targets),\n",
    "                        epochs=num_epochs, batch_size=1, verbose=0)\n",
    "    mae_history = history.history['val_mean_absolute_error']\n",
    "    all_mae_histories.append(mae_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}