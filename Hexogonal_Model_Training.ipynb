{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "import datetime\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import os, shutil\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageColor\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.multioutput import RegressorChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_dir ='\\\\Users\\\\danie\\\\Penn_State_REU_Jupyter\\\\Hexagon ML Project GitHub\\\\Training_set_6_15' \n",
    "test_dataset_dir='\\\\Users\\\\danie\\\\Penn_State_REU_Jupyter\\\\Hexagon ML Project GitHub\\\\Testing_set_6_16' \n",
    "\n",
    "df=pd.read_csv(os.path.join(train_dataset_dir,\"training_dataframe.csv\"))\n",
    "df = df.sample(frac=1,random_state=5).reset_index(drop=True)\n",
    "\n",
    "dft = pd.read_csv(os.path.join(test_dataset_dir,\"training_dataframe.csv\"))\n",
    "dft = dft.sample(frac=1,random_state=5).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(121500, 9)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.shape\n",
    "#dft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()                                  \n",
    "    model.add(layers.Conv2D(32, (3,3) ,activation='relu', input_shape=(32,32,1)))\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Flatten())\n",
    "    #model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     5,
     17
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 97200 validated image filenames.\nFound 24300 validated image filenames.\n"
    }
   ],
   "source": [
    "#Creates generators for training and validation images\n",
    "SEED=5\n",
    "validation_split_frac=0.2\n",
    "batch_size=256\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,validation_split=validation_split_frac)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  \n",
    "train_generator= train_datagen.flow_from_dataframe(\n",
    "        df,\n",
    "        directory=train_dataset_dir,\n",
    "        x_col=\"filename\",\n",
    "        y_col=['x_coord','y_coord','neighbor1x','neighbor1y','neighbor2x','neighbor2y','neighbor3x','neighbor3y'],\n",
    "        target_size=(32,32),\n",
    "        shuffle=True,\n",
    "        color_mode='grayscale',\n",
    "        seed= SEED,\n",
    "        class_mode=\"raw\",\n",
    "        batch_size=batch_size,\n",
    "        subset='training')\n",
    "\n",
    "validation_generator= train_datagen.flow_from_dataframe(\n",
    "        df,\n",
    "        directory=train_dataset_dir,\n",
    "        x_col=\"filename\",\n",
    "        y_col=['x_coord','y_coord','neighbor1x','neighbor1y','neighbor2x','neighbor2y','neighbor3x','neighbor3y'],\n",
    "        target_size=(32,32),\n",
    "        shuffle=True,\n",
    "        color_mode='grayscale',\n",
    "        seed= SEED,\n",
    "        class_mode=\"raw\",\n",
    "        batch_size=batch_size,\n",
    "        subset='validation')\n",
    "\n",
    "# test_generator= test_datagen.flow_from_dataframe(\n",
    "#         dft,\n",
    "#         directory=test_dataset_dir,\n",
    "#         x_col=\"filename\",\n",
    "#         y_col=['x_coord','y_coord','neighbor1x','neighbor1y','neighbor2x','neighbor2y','neighbor3x','neighbor3y'],\n",
    "#         target_size=(32,32),\n",
    "#         shuffle=True,\n",
    "#         seed= SEED,\n",
    "#         class_mode=\"raw\",\n",
    "#         batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Reusing TensorBoard on port 6006 (pid 3588), started 21:26:08 ago. (Use '!kill 3588' to kill it.)"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from tensorboard import notebook\n",
    "# notebook.list()\n",
    "%tensorboard --logdir Training_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [],
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\nWARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\nTrain for 379 steps, validate for 94 steps\nEpoch 1/40\n379/379 [==============================] - 74s 195ms/step - loss: 0.0746 - mae: 0.2334 - mape: 1015043.3125 - val_loss: 0.0744 - val_mae: 0.2333 - val_mape: 1044194.0625\nEpoch 2/40\n379/379 [==============================] - 54s 141ms/step - loss: 0.0743 - mae: 0.2331 - mape: 1034787.5625 - val_loss: 0.0744 - val_mae: 0.2333 - val_mape: 1044190.8125\nEpoch 3/40\n379/379 [==============================] - 52s 138ms/step - loss: 0.0743 - mae: 0.2331 - mape: 1035580.9375 - val_loss: 0.0744 - val_mae: 0.2333 - val_mape: 1050863.7500\nEpoch 4/40\n379/379 [==============================] - 54s 142ms/step - loss: 0.0743 - mae: 0.2331 - mape: 1034889.5000 - val_loss: 0.0744 - val_mae: 0.2333 - val_mape: 1043696.0625\nEpoch 5/40\n379/379 [==============================] - 50s 132ms/step - loss: 0.0743 - mae: 0.2331 - mape: 1035784.2500 - val_loss: 0.0744 - val_mae: 0.2333 - val_mape: 1042259.5625\nEpoch 6/40\n379/379 [==============================] - 50s 131ms/step - loss: 0.0743 - mae: 0.2331 - mape: 1035297.8750 - val_loss: 0.0744 - val_mae: 0.2333 - val_mape: 1051000.1250\nEpoch 7/40\n379/379 [==============================] - 49s 130ms/step - loss: 0.0743 - mae: 0.2331 - mape: 1036458.0000 - val_loss: 0.0744 - val_mae: 0.2333 - val_mape: 1044607.3750\nEpoch 8/40\n379/379 [==============================] - 48s 127ms/step - loss: 0.0743 - mae: 0.2331 - mape: 1035098.9375 - val_loss: 0.0744 - val_mae: 0.2333 - val_mape: 1046372.6875\nEpoch 9/40\n379/379 [==============================] - 48s 128ms/step - loss: 0.0743 - mae: 0.2331 - mape: 1034884.3125 - val_loss: 0.0744 - val_mae: 0.2333 - val_mape: 1048638.0000\nEpoch 10/40\n379/379 [==============================] - 48s 126ms/step - loss: 0.0743 - mae: 0.2331 - mape: 1035691.4375 - val_loss: 0.0744 - val_mae: 0.2333 - val_mape: 1043328.5000\nEpoch 11/40\n379/379 [==============================] - 48s 127ms/step - loss: 0.0743 - mae: 0.2331 - mape: 1036290.8125 - val_loss: 0.0744 - val_mae: 0.2333 - val_mape: 1048976.1250\nEpoch 12/40\n379/379 [==============================] - 49s 129ms/step - loss: 0.0743 - mae: 0.2331 - mape: 1035315.4375 - val_loss: 0.0744 - val_mae: 0.2333 - val_mape: 1046196.3125\nEpoch 13/40\n379/379 [==============================] - 49s 128ms/step - loss: 0.0743 - mae: 0.2331 - mape: 1037372.0000 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1046381.6875\nEpoch 14/40\n379/379 [==============================] - 48s 127ms/step - loss: 0.0743 - mae: 0.2331 - mape: 1036275.0000 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1048716.3750\nEpoch 15/40\n379/379 [==============================] - 48s 128ms/step - loss: 0.0743 - mae: 0.2331 - mape: 1036143.0000 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1042938.3750\nEpoch 16/40\n379/379 [==============================] - 48s 127ms/step - loss: 0.0743 - mae: 0.2331 - mape: 1035080.3125 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1039251.5000\nEpoch 17/40\n379/379 [==============================] - 48s 127ms/step - loss: 0.0743 - mae: 0.2331 - mape: 1036027.0000 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1045772.5000\nEpoch 18/40\n379/379 [==============================] - 49s 130ms/step - loss: 0.0743 - mae: 0.2331 - mape: 1034438.0625 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1047490.1875\nEpoch 19/40\n379/379 [==============================] - 48s 128ms/step - loss: 0.0743 - mae: 0.2331 - mape: 1035816.0625 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1049368.3750\nEpoch 20/40\n379/379 [==============================] - 50s 132ms/step - loss: 0.0743 - mae: 0.2331 - mape: 1035402.7500 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1050086.2500\nEpoch 21/40\n379/379 [==============================] - 50s 131ms/step - loss: 0.0743 - mae: 0.2331 - mape: 1036207.5625 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1045372.1875\nEpoch 22/40\n379/379 [==============================] - 48s 127ms/step - loss: 0.0743 - mae: 0.2331 - mape: 1036284.8750 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1051078.5000\nEpoch 23/40\n379/379 [==============================] - 49s 129ms/step - loss: 0.0743 - mae: 0.2331 - mape: 1037332.8125 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1043624.8750\nEpoch 24/40\n379/379 [==============================] - 48s 127ms/step - loss: 0.0742 - mae: 0.2331 - mape: 1034723.7500 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1042370.3125\nEpoch 25/40\n379/379 [==============================] - 49s 128ms/step - loss: 0.0742 - mae: 0.2331 - mape: 1035970.1875 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1042217.6250\nEpoch 26/40\n379/379 [==============================] - 49s 129ms/step - loss: 0.0742 - mae: 0.2331 - mape: 1036015.5000 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1046783.8125\nEpoch 27/40\n379/379 [==============================] - 49s 128ms/step - loss: 0.0742 - mae: 0.2331 - mape: 1035076.7500 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1045875.6875\nEpoch 28/40\n379/379 [==============================] - 49s 129ms/step - loss: 0.0742 - mae: 0.2331 - mape: 1035927.6875 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1048289.0000\nEpoch 29/40\n379/379 [==============================] - 51s 135ms/step - loss: 0.0742 - mae: 0.2331 - mape: 1034659.6250 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1042343.3125\nEpoch 30/40\n379/379 [==============================] - 49s 130ms/step - loss: 0.0742 - mae: 0.2331 - mape: 1035050.1875 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1045284.0000\nEpoch 31/40\n379/379 [==============================] - 49s 128ms/step - loss: 0.0742 - mae: 0.2331 - mape: 1036141.3125 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1046625.4375\nEpoch 32/40\n379/379 [==============================] - 51s 133ms/step - loss: 0.0742 - mae: 0.2331 - mape: 1035800.8125 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1046129.9375\nEpoch 33/40\n379/379 [==============================] - 50s 131ms/step - loss: 0.0742 - mae: 0.2331 - mape: 1035784.1250 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1048609.2500\nEpoch 34/40\n379/379 [==============================] - 50s 133ms/step - loss: 0.0742 - mae: 0.2331 - mape: 1035345.6875 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1048819.8750\nEpoch 35/40\n379/379 [==============================] - 48s 126ms/step - loss: 0.0742 - mae: 0.2332 - mape: 1035716.5000 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1046004.6875\nEpoch 36/40\n379/379 [==============================] - 47s 125ms/step - loss: 0.0742 - mae: 0.2331 - mape: 1035551.5625 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1049087.6250\nEpoch 37/40\n379/379 [==============================] - 48s 127ms/step - loss: 0.0742 - mae: 0.2332 - mape: 1037165.5625 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1044528.2500\nEpoch 38/40\n379/379 [==============================] - 51s 135ms/step - loss: 0.0742 - mae: 0.2332 - mape: 1035921.1875 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1045099.7500\nEpoch 39/40\n379/379 [==============================] - 48s 127ms/step - loss: 0.0742 - mae: 0.2332 - mape: 1035671.7500 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1047490.4375\nEpoch 40/40\n379/379 [==============================] - 49s 128ms/step - loss: 0.0742 - mae: 0.2331 - mape: 1035300.8125 - val_loss: 0.0743 - val_mae: 0.2333 - val_mape: 1049081.7500\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1f2fdedc448>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "model=build_model()\n",
    "model.compile(optimizer='sgd', loss='mse', metrics=['mae','mape'])\n",
    "#model.summary()\n",
    "num_epochs=40\n",
    "training_steps=int(df.shape[0]*(1-validation_split_frac)/batch_size)\n",
    "validation_steps=int(df.shape[0]*validation_split_frac/batch_size)\n",
    "#assert (training_steps+validation_steps)*batch_size == df.shape[0]\n",
    "log_dir = os.path.join(\"Training_logs\\\\fit\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=training_steps,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1, \n",
    "    callbacks=[tensorboard_callback]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From D:\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nINFO:tensorflow:Assets written to: 40erun6_17\\assets\n"
    }
   ],
   "source": [
    "model.save(\"40erun6_17\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.load_model('60epochrun6_16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\n42/42 [==============================] - 4s 91ms/step - loss: 0.0112 - mae: 0.0784\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0.011231104200262399, 0.078366056]"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "#Evaluates the model on testing set\n",
    "testing_steps=dft.shape[0]//batch_size\n",
    "log_dir = os.path.join(\"Training_logs\\\\test\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "model.evaluate(\n",
    "    test_generator,\n",
    "    steps=testing_steps\n",
    "    #callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['loss', 'mae']"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the scale of two dimensional materials, stretching or straining the atomic lattice can have an enormous impact on the material properties of whatever you're working with. We can take photos of these materials with atomic resoution, however, the exact distribution of these atoms is hard to characterize by eye, and small strain of 1-2% is almost impossible to distinguish at first glance. My project is to design a machine learning model that can automaticaly detect the strain of a honeycomb lattice, even when that strain is small and varrying across an image. This would allow researchers to compare the strain of a material to its electronic properties and other observables, unveiling connections we haven't been able to see before. Many 2D materials are poorly understood, and this project could help answer many questions about how 2D phenomenon arise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}