{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.mlab as mlab\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow.keras.losses\n",
    "import math\n",
    "import datetime\n",
    "from my_classes import DataGenerator,STMImage\n",
    "from scipy.ndimage.filters import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 264       \n",
      "=================================================================\n",
      "Total params: 93,608\n",
      "Trainable params: 93,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_name='run6_24_newdataset'\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "model=models.load_model(os.path.join('Models',model_name),compile=False)\n",
    "model.compile(optimizer='Adam', loss=root_mean_squared_error, metrics=['mse','mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": [
     2,
     13,
     18
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ARRAY:Loads in a single testing image and plots its prediction vs true labels\n",
    "#Method for separting label array into useful data points\n",
    "def split_label(labels):\n",
    "    center_atom=np.array([labels[0],labels[1]])*32\n",
    "    neighborvec1=np.array([labels[2],labels[3]])*32\n",
    "    neighborvec2=np.array([labels[4],labels[5]])*32\n",
    "    neighborvec3=np.array([labels[6],labels[7]])*32\n",
    "    neighbors=[]\n",
    "    neighbors.append(center_atom+neighborvec1)\n",
    "    neighbors.append(center_atom+neighborvec2)\n",
    "    neighbors.append(center_atom+neighborvec3)\n",
    "    return center_atom , neighbors \n",
    "#Methods for coloring in the central atom and labels on the images.\n",
    "def plot_labels():\n",
    "    plt.plot(center_atom[0],center_atom[1],'o',color='black')\n",
    "    plt.plot(neighbors[0][0],neighbors[0][1],'o',color='red')\n",
    "    plt.plot(neighbors[1][0],neighbors[1][1],'o',color='green')\n",
    "    plt.plot(neighbors[2][0],neighbors[2][1],'o',color='blue')\n",
    "def plot_test_labels():\n",
    "    plt.plot(center_atom_t[0],center_atom_t[1],'o',color='xkcd:gray')\n",
    "    plt.plot(neighbors_t[0][0],neighbors_t[0][1],'o',color='xkcd:dark red')\n",
    "    plt.plot(neighbors_t[1][0],neighbors_t[1][1],'o',color='xkcd:dark green')\n",
    "    plt.plot(neighbors_t[2][0],neighbors_t[2][1],'o',color='xkcd:dark blue')\n",
    "\n",
    "    \n",
    "\n",
    "model_name='run6_30_padding'\n",
    "test_dataset_dir ='\\\\Users\\\\danie\\\\Penn_State_REU_Jupyter\\\\Hexagon ML Project GitHub\\\\Training_set_6_29'\n",
    "prediction_dir=os.path.join(\"Training_Set_Predictions\",model_name)\n",
    "dft = pd.read_csv(os.path.join(test_dataset_dir,\"training_dataframe.csv\"))\n",
    "dfp= pd.read_csv(os.path.join(prediction_dir,\"predictions_dataframe.csv\"))\n",
    "\n",
    "\n",
    "index=21642\n",
    "im_filename=dft['filename'][index]\n",
    "atom_size=dft['atom_size'][index]\n",
    "corr=dft['corr'][index]+.1\n",
    "\n",
    "#test_im=np.asarray(image.load_img(os.path.join(test_dataset_dir,im_filename)))\n",
    "test_im=np.load(os.path.join(test_dataset_dir,im_filename))\n",
    "# im_tensor=np.reshape(test_im,(32,32,1))\n",
    "# im_tensor=np.expand_dims(im_tensor, axis=0)\n",
    "\n",
    "label_names=['x_coord','y_coord','neighbor1x','neighbor1y','neighbor2x','neighbor2y','neighbor3x','neighbor3y']\n",
    "test_labels=dft[label_names].loc[index].to_numpy()\n",
    "prediction_labels=dfp[label_names].loc[index].to_numpy()\n",
    "\n",
    "center_atom_t,neighbors_t=split_label(test_labels)\n",
    "center_atom,neighbors=split_label(prediction_labels)\n",
    "\n",
    "#os.makedirs(os.path.join('Prediction_Plots',datetime.datetime.now().strftime(\"%m_%d\")))\n",
    "prediction_plots_dir=os.path.join('Prediction_Plots',datetime.datetime.now().strftime(\"%m_%d\"))\n",
    "\n",
    "# %matplotlib notebook\n",
    "# %matplotlib inline\n",
    "\n",
    "\n",
    "im=STMImage(test_im)\n",
    "fig = plt.figure(figsize = (8, 8))\n",
    "ax = plt.subplot(1,1,1)\n",
    "ax.imshow(im.image)\n",
    "ax.axis('off')\n",
    "plot_test_labels()\n",
    "#plot_labels()\n",
    "\n",
    "\n",
    "im_tensor=STMImage(test_im).image\n",
    "im_tensor=np.expand_dims(im_tensor, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-6735499d0699>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mactivation_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayer_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mactivations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactivation_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m   1014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[1;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m               \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m               total_epochs=1)\n\u001b[0m\u001b[0;32m    476\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    636\u001b[0m               *args, **kwds)\n\u001b[0;32m    637\u001b[0m       \u001b[1;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "layer_outputs=[layer.output for layer in model.layers[:8]]\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "activations = activation_model.predict(im_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_name='run6_30_padding'\n",
    "plot_dir=os.path.join(\"Layer Activations\",model_name)\n",
    "#os.makedirs(plot_dir)\n",
    "layer_names = []                                                          \n",
    "for layer in model.layers[:8]:                                            \n",
    "    layer_names.append(layer.name)                                        \n",
    "\n",
    "images_per_row = 16\n",
    "\n",
    "plt.figure()\n",
    "for layer_name, layer_activation in zip(layer_names, activations):      \n",
    "    n_features = layer_activation.shape[-1]                               \n",
    "\n",
    "    size = layer_activation.shape[1]                                      \n",
    "\n",
    "    n_cols = n_features // images_per_row                                 \n",
    "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "\n",
    "    for col in range(n_cols):                                             \n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[0,\n",
    "                                             :, :,\n",
    "                                             col * images_per_row + row]\n",
    "            channel_image -= channel_image.mean()                         \n",
    "            channel_image /= channel_image.std()\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            display_grid[col * size : (col + 1) * size,                   \n",
    "                         row * size : (row + 1) * size] = channel_image\n",
    "\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                        scale * display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
    "    plt.savefig(os.path.join(plot_dir,'run6_24_newdataset activations'+layer_name+'.png'))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
